```
计算机基础八股文（算法，网络），八股文(java（jvm，网络，多线程，javase）,框架(hdfs,mr,yarn,hive,spark),javaweb)，项目（数仓（电商场景，TI），web）,笔试（算法题，sql题）
其他：linux环境下的shell及日常使用，git使用，maven使用，nginx，docker
```

```
项目模块实际也对应八股文内容，一个技术或框架由项目部分（用法、api、业务经验（清除每个细节））和理论部分（八股文）构成，本质就是掌握这两者，两者进阶就对应着项目（用法->项目）和源码（理论->源码级别理论）。
```

```
框架这一块：辅助组件(zookeeper，kafka)，数据采集迁移框架(flume，logtash，sqoop,kettle)，数仓(hadoop,hive)，查询分析框架(spark,kylin,presto,phoenix)，可视化框架(superset)，整体流程控制(azkaban)，数据库（es，mysql）
```

```
hivesql
kettle etl
superset bi报表可视化
```

```
常见业务场景：电商，银行证券基金保险，物联网（如温度传感器，网卡设备等，车联网），媒体（短视频，文本等）
```

```
关于简历，展现部分很重要，如项目效果、个人博客等。
```

```
#面经查漏补缺
https://www.nowcoder.com/discuss/792950?channel=-1&source_id=profile_follow_post_nctrack
https://www.nowcoder.com/discuss/719344?source_id=discuss_experience_nctrack&channel=-1
https://www.nowcoder.com/discuss/916657?source_id=discuss_experience_nctrack&channel=-1
https://www.nowcoder.com/discuss/842391?source_id=discuss_experience_nctrack&channel=-1
https://www.nowcoder.com/discuss/868723?source_id=discuss_experience_nctrack&channel=-1
#coursera上的课程，项目
https://www.coursera.org/specializations/big-data
#github iot spark，项目
https://github.com/harsh86/iot-traffic-monitor-flink
```

```
7月提前批，提前批没有笔试，难度较低。
项目一般写相关性强的2-3个项目，项目做了什么，使用了什么技术，要对项目非常熟悉。项目背景，项目挑战，负责内容。
技术栈，项目与实习，奖项，学历

一面：基础知识+算法+项目内容
二面：压力面
基础知识+算法+项目内容，难度加大
表现形式：问的深，连环追击，发散性强，打压
方法：会多少说多少，不会就说不清楚
三面：总监面
开放性问题，
hr面，表现稳定性，合作能力，意愿
反问：团队是做什么，那一个团队

offer选择
流程：意向书->谈薪资（10月中旬开始）->正式offer（10月下旬）
核心业务，薪资，平台

科院内容：根据相关性准备，不相关则不提及。若不相关，但是问及科研内容，主要考察表达能力，只要讲清楚即可。
offershow
银行信息岗：有轮岗
在牛客网搜集信息，查看面经，尝试逐个回答，在官网投递简历。

准备思路清晰的ppt，面试的主动性
```

```
如果需要描述项目的困难和挑战，一般描述技术上的困难、业务场景的困难，不要提逻辑上的困难，没有含量。
如技术上的如何解决倾斜、如何解决并发访问、如何确保精确一次消费、
场景上的如何解决活动流量爆发、地区订单数据倾斜、如何进行订单去重、如何处理UV和PV指标。
```

## 理论知识0817
### Java八股
#### equals和==区别，为什么重写equals要重写hashcode
>==是比较两个变量的值是否相等，如果相等返回true否则false。equals则是先比较两个变量的地址，如果相等返回True，否则进一步比较值，如果相等返回true，否则false。equals表示两个变量值是否是相等，hashcode也表示两个变量是否是同一个东西，这两者必须保持一致，也就是equals返回true时，hashcode必须相等，但hashcode一样，不一定equals为true。

### java集合有哪些
>collection下有List，Set，Map。再细分有ArrayList，LinkedList，HashMap

### ArrayList和LinkedList区别
>ArrayList底层是基于数组实现的，所有它的随机读写很快，能通过索引快速找到值。但是在删除某一个元素或添加某一个元素到数组中间时，其需要挪动插入位置之后的所有元素，所以复杂度较高。LinkedList底层基于链表，其添加元素和删除元素比较方便，只需要将相邻的链表节点进行修改。但是其在查找元素时，只能顺序遍历链表的节点，所以效率较差。

### HashMap默认大小，扩容机制
> HashMap结构是什么样的？什么时候扩容？扩到多少？

### HashMap在哪个版本使用红黑树，之前是使用什么?
> jdk8，之前使用键值对和链表。

### 线程的创建方式
> 1使用一个类实现Runnable接口，然后调用run方法
> 2直接使用Thread

### 多线程了解
> 线程的状态：
> 线程状态的转换：
> 多线程的常用编程：

### MySQL的索引，b树与b+树区别
> MySQL使用b+树构建索引，b+树的每个节点由指向下一层的指针以及值构成，两者互相间隔，指针数比值数目多1。通过与值比较确认所在的子树，从而进入下一层，重复此过程到达叶子节点。b树的查找结果可以分布在非叶子节点，而b+树全部在叶子节点，这样每个查询的时间都相近，保持了查询性能的稳定性。

### Redis了解
>Redis是一个内存数据库，有高并发，高速度的特点，因为其数据都是维持在内存中的，可以保持较高的访问速度。
>Rdis提供了一些常用的数据结构，如String，List，Set，Map，ZSset（有序set）。Redis可以用于一些临时数据的存储，因为其无法保持较高的可靠性，可能导致数据的丢失。可以用来存储当日平台的用户日活信息等，帮助编写实时处理的逻辑。

### 介绍一下Spark
>Spark是一个大数据计算引擎，其是在Hadoop之后提出的，相比于Hadoop其执行速度获得了很大的提升。因为其使用内存作为存储媒介，减少了磁盘的交互次数，提升了效率，同时也对设备的内存提出了较高的要求。其提出了弹性分布式数据集RDD，RDD是对分布在多台机器上的数据集的描述，spark的操作都是基于rdd和算子进行的，算子可以对rdd执行各种操作，例如map，reduce，take，show等，当有action算子调用时，就会进行计算。
>Spark的架构：Spark的具体任务由executor执行，executor接受来自master的任务，并在所在机器执行，并返回结果给master。master和worker这是节点，executor这是spark的抽象架构程序。
>Spark on yarn：Spark on yarn模式通过将yarn作为资源管理器，提供了集群资源管理功能。executor的创建需要相yarn申请对应的资源，然后才能获得创建的权限。

### RDD为什么弹性
>弹性就是指他能适应集群这种环境1可以在多个节点上分布，适应集群的计算环境，不同集群节点都可以运行同样的rdd程序。2容错性：当发生故障时，rdd可以进行恢复，通过读取持久化的rdd或从头重新计算rdd来恢复计算任务，不会让任务直接崩溃。

### Spark Stage 划分
>Spark程序在rdd上执行算法来完成任务，当执行算子时我们得到一个新的rdd，这两个rdd构成了前后依赖的关系，通过依赖的宽窄来划分，宽依赖是指后续的rdd一个分区依赖于多个前边rdd的分区，这导致需要等待前边的多个分区计算完成后边的rdd才能开始计算，宽依赖的两个rdd需要很长时间的等待，宽依赖会被划分为两个stage。窄依赖是指后方的rdd只依赖于前方rdd的一个分区，一个分区计算完成后，可以直接传递给下一个rdd并开始计算，这种依赖不会划分为多个stage。

### spark的cache，persist，checkpoint
>cache 是指缓存到内存中，当发生故障时，被缓存过的rdd不需要从头计算，减少了计算的量。persist是指持久化rdd到外部媒介，例如磁盘。cache和persist不是action算子，会懒执行。checkpoint是指进行快照，保存当前的rdd状态。

### Spark数据倾斜处理方法
>找到数据倾斜的任务，以及是哪一个key发生了数据倾斜的现象。对这个key增加前缀，1将数据分布到多个分区上去，减少分区的压力。2可以将该key单独拿出来作为一个任务，其他数据量较少的作为一个key，这样数据量少的执行速度不会受到影响。

### Linux查看内存，cpu状态，查看进程的内存消耗和cpu消耗
>  free 查看内存
>  top 查看当前cpu，进程的内存消耗的cpu消耗

### clickhouse
>clickhouse 是一个olap数据库，可以实时分析所需要的数据。
>olap场景的特点就是绝大多数是读请求，已添加的数据不能修改，可能取很多行但是很少列，需要行的高吞吐量，事务不必须，数据一致性要求低。从数据变化（不修改），查询什么（读请求，行多列少），特性对比（事务不必须，一致性要求低），压缩算法你（数据压缩允许在内存中缓存更多数据）

### 参考
>https://www.nowcoder.com/discuss/842391


# 数据仓库工具箱
## 第10节 金融服务
>金融服务涉及各行业，如信用卡公司，抵押贷款提供商等，日常接触的零售银行。一家银行提供广泛的产品，包括活期存款，储蓄账户，按揭贷款，个人贷款，信用卡以及银行贵重物品保险箱等。
>主要讨论如下概念：
>银行总线矩阵片段
>对维度进行分类以避免维度太少的陷阱
>家庭维度
>用一个账户关联多个客户的桥接表，以及权重因子。
>报表的动态范围值实时

### 银行案列研究与总线矩阵

>业务用户希望看到每个账户5年的，以月为单位的历史快照数据。
>每个账户有一个基本的余额。业务上希望用同一个分析来分组不同类型的账户并比较余额
>每个类型的账户（银行的产品）有一系列自定义维度属性和数值事实，其内容不同的产品差异大
>每个账户认为属于某一家庭。因为婚姻状况变化和其他不同生命阶段因素，导致账户家庭关系产生大量变化（每天都有人死亡，结婚，离婚）
>除了家庭之外，对人口统计信息关注，以个人或家庭为单位。此外，关注每个账户和家庭的行为积分，如存储行为等特征

### 对维度进行分类以避免维度太少的陷阱
>对于用户月快照事实表这个需求，一般需要在dwd层建立一个周期型快照事实表，ods使用全量数据同步。dwd层再去关联其他事实表的维度，例如家庭维度，账户维度，产品维度，账户状态维度。这里的维度数量很多，将他们放在一起是不行的，因为会造成单个表数据量过大，而且在业务场景中家庭，产品这些都是分块的功能。我们可以按照家庭，产品，账户等建立多个表，然后关联到月份周期型快照事实表，这和一个星型模型建模类似，一个事实表关联多个表。

### 家庭维度
>从银行角度，家庭可能由几个账户和独立的账户拥有人构成。构建商业上的家庭需要设计业务规则和算法以将账户分配到家庭中。
>之所以将家庭和账户维度分开是因为，账户维度的大小和家庭维度不一致，如1000万条账户可能只有300万条家庭数据，导致重复存储家庭数据。而且家庭维度中的账户有很大波动性，家庭维度为与事实表关联提供了更小的入口点，不需要遍历1000万条事实表数据。将家庭与账户分开可以应对两者的不同数据量，以及应对家庭关系中的账户发生频繁的变化。

### 多值维度与权重因子
>在账户维度表中，一个账户可以对应多个客户，多个客户共同拥有此账户，显然这种1对n的关系，无法将客户作为账户维度表的一个属性。我们可以再建立一个桥接表，桥接客户和账户，在该表中描述这种1对多的关系，使用客户表主键和账户表主键关联两个表的数据。
>权重因子，为同一个账户的客户分配权重，其和为1。权重因子是为了在计算以客户为基础的一些事实时，给客户分配可加的事实。

### 报表的动态范围值实时
>假设需要查询范围值报表的能力，如需要余额在0-100,100-500,500-550。可以将这一组分组规则存储在一个单独的范围定义表，使用一个lower value和upper value代表一个范围，同一个group_name的是同一组分组规则。范围定义表属性有 lower value,upper value,group name.
