[TOC]
# BERT
>BERT Encoder 编码层主要功能是学习文本单
词级别的信息，便于得到文本的词嵌入。在此，
借助双向 Transformer 编码器学习单词的上下文语
境，以期望获得丰富的单词级别特征信息，从而
有 效 解 决 一 词 多 义 问 题 。 BERT 是采用双向
Transformer 编码器的语言表征模型
# LSTM
>LSTM 使用门的结构去除或增加信息到记忆单元的状态变
量，通过遗忘门、输入门、输出门控制信息的记
忆和遗忘，从而解决实体的长期依赖问题。
# CRF
>CRF 标签解码层主要功能是对输入向量进行
解码，预测单词的实体标签。条件随机场 CRF 可
以感知相邻实体标签的依赖关系，确保最终预测
标签的合理性，从而提升识别的准确率。
# 自注意力
>自注意力网络的主要功能是关注句子中的重
要单词，为实体识别的关键词分配更高的权重，
从而注意到不同单词的差异，便于得到注意力机
制加权的新向量。自注意力(self-attention)网络可
以为输入特征分配不同的权重，重点注意关键的
特征